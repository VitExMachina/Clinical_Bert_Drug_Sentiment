{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RncCRSFfECS",
    "outputId": "2ae7807e-71b9-4492-d462-aa8bc94c70be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       urlDrugName  rating         effectiveness  \\\n",
      "0        2202         enalapril       4      Highly Effective   \n",
      "1        3117  ortho-tri-cyclen       1      Highly Effective   \n",
      "2        1146           ponstel      10      Highly Effective   \n",
      "3        3947          prilosec       3  Marginally Effective   \n",
      "4        1951            lyrica       2  Marginally Effective   \n",
      "\n",
      "           sideEffects                               condition  \\\n",
      "0    Mild Side Effects  management of congestive heart failure   \n",
      "1  Severe Side Effects                        birth prevention   \n",
      "2      No Side Effects                        menstrual cramps   \n",
      "3    Mild Side Effects                             acid reflux   \n",
      "4  Severe Side Effects                            fibromyalgia   \n",
      "\n",
      "                                      benefitsReview  \\\n",
      "0  slowed the progression of left ventricular dys...   \n",
      "1  Although this type of birth control has more c...   \n",
      "2  I was used to having cramps so badly that they...   \n",
      "3  The acid reflux went away for a few months aft...   \n",
      "4  I think that the Lyrica was starting to help w...   \n",
      "\n",
      "                                   sideEffectsReview  \\\n",
      "0  cough, hypotension , proteinuria, impotence , ...   \n",
      "1  Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...   \n",
      "2         Heavier bleeding and clotting than normal.   \n",
      "3  Constipation, dry mouth and some mild dizzines...   \n",
      "4  I felt extremely drugged and dopey.  Could not...   \n",
      "\n",
      "                                      commentsReview  \n",
      "0  monitor blood pressure , weight and asses for ...  \n",
      "1  I Hate This Birth Control, I Would Not Suggest...  \n",
      "2  I took 2 pills at the onset of my menstrual cr...  \n",
      "3  I was given Prilosec prescription at a dose of...  \n",
      "4                                          See above  \n"
     ]
    }
   ],
   "source": [
    "#load tsv data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "\n",
    "drug_test_data = pd.read_csv(\"data/drugLibTest_raw.tsv\", sep='\\t')\n",
    "drug_train_data = pd.read_csv(\"data/drugLibTrain_raw.tsv\", sep='\\t')\n",
    "\n",
    "#combine train and test data\n",
    "drug_data = pd.concat([drug_train_data, drug_test_data], ignore_index=True)\n",
    "\n",
    "#display first few rows of the dataframe\n",
    "print(drug_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mEsVxWwfECT",
    "outputId": "c42a095f-eb09-4658-f7dc-38076f54372f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0            0\n",
      "urlDrugName           0\n",
      "rating                0\n",
      "effectiveness         0\n",
      "sideEffects           0\n",
      "condition             1\n",
      "benefitsReview       23\n",
      "sideEffectsReview    98\n",
      "commentsReview       13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for missing value counts\n",
    "print(drug_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-VZV_HDfECT"
   },
   "outputs": [],
   "source": [
    "#drop rows with missing values\n",
    "drug_data = drug_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "id": "uzPCs0zjfECT",
    "outputId": "7fcecf19-ed43-4af0-fc66-21a7605865fd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4013,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1202,\n        \"min\": 0,\n        \"max\": 4161,\n        \"num_unique_values\": 4013,\n        \"samples\": [\n          71,\n          3444,\n          771\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"urlDrugName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 534,\n        \"samples\": [\n          \"azopt\",\n          \"saizen\",\n          \"tri-luma\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          1,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"effectiveness\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Marginally Effective\",\n          \"Moderately Effective\",\n          \"Ineffective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sideEffects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Severe Side Effects\",\n          \"Moderate Side Effects\",\n          \"No Side Effects\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"condition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1754,\n        \"samples\": [\n          \"cold\",\n          \"unable to sleep because of pain\",\n          \"bacterial growth\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefitsReview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3922,\n        \"samples\": [\n          \"I had to wait quite a few month before Accutan had started to work but by the end of the treatment my skin was like a babies. Not oily at all even my pores shrank and there was no acne on my face. The down side was that after not taking the medicine any more after a couple of month with great skin the acne has started to come back.\",\n          \"Increased hair growth in the thinning areas on the head, making the hair look fuller. I also experienced less hair falling out.\",\n          \"weight loss, better awareness of how much fat is in foods.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sideEffectsReview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3715,\n        \"samples\": [\n          \"There were no side effects that I am aware of. My husband has now also begun treatment after trying diet only.\",\n          \"I am fortunate in saying that there are no side effects at the dose I am taking.\",\n          \"The major side effect of drowsiness is desirable in my case, but it also has a marked side effect of weight gain.  In addition, there is a dry mouth effect that seems to resolve after a month or two.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commentsReview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3941,\n        \"samples\": [\n          \"I take 100 mg. a day of prometrium and covaryx hs at .625 mg. 4 times a week. I am very pleased with this combination of the two drugs. I feel great and have a lot of energy. I am very healthy and have no health issues. I am not at risk for breast cancer so I am not afraid of HRT.\",\n          \"Treatment entails applying one patch per week.\",\n          \"Lost 91 lbs. in 6-7 months. Kept the weight off even to this day (4 years later) b/c the Meridia taught me the key to weight loss: Less calorie intake. And since the Meridia trained my body to get full quicker, I was able to still eat & crave less even after getting off of the medication.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f8d3655e-f82f-4070-b915-5de2c32e5f6d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2202</td>\n",
       "      <td>enalapril</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>management of congestive heart failure</td>\n",
       "      <td>slowed the progression of left ventricular dys...</td>\n",
       "      <td>cough, hypotension , proteinuria, impotence , ...</td>\n",
       "      <td>monitor blood pressure , weight and asses for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3117</td>\n",
       "      <td>ortho-tri-cyclen</td>\n",
       "      <td>1</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>birth prevention</td>\n",
       "      <td>Although this type of birth control has more c...</td>\n",
       "      <td>Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...</td>\n",
       "      <td>I Hate This Birth Control, I Would Not Suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1146</td>\n",
       "      <td>ponstel</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>menstrual cramps</td>\n",
       "      <td>I was used to having cramps so badly that they...</td>\n",
       "      <td>Heavier bleeding and clotting than normal.</td>\n",
       "      <td>I took 2 pills at the onset of my menstrual cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3947</td>\n",
       "      <td>prilosec</td>\n",
       "      <td>3</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>acid reflux</td>\n",
       "      <td>The acid reflux went away for a few months aft...</td>\n",
       "      <td>Constipation, dry mouth and some mild dizzines...</td>\n",
       "      <td>I was given Prilosec prescription at a dose of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1951</td>\n",
       "      <td>lyrica</td>\n",
       "      <td>2</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>fibromyalgia</td>\n",
       "      <td>I think that the Lyrica was starting to help w...</td>\n",
       "      <td>I felt extremely drugged and dopey.  Could not...</td>\n",
       "      <td>See above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>690</td>\n",
       "      <td>accutane</td>\n",
       "      <td>7</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>acne vulgaris</td>\n",
       "      <td>Detoxing effect by pushing out the system thro...</td>\n",
       "      <td>Hairloss, extreme dry skin, itchiness, raises ...</td>\n",
       "      <td>Treatment period is 3 months/12 weeks. Dosage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>1071</td>\n",
       "      <td>proair-hfa</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>asthma</td>\n",
       "      <td>The albuterol relieved the constriction, irrit...</td>\n",
       "      <td>I have experienced no side effects.</td>\n",
       "      <td>I use the albuterol as needed because of aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>681</td>\n",
       "      <td>accutane</td>\n",
       "      <td>8</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>serve acne</td>\n",
       "      <td>Serve Acne has turned to middle</td>\n",
       "      <td>Painfull muscles, problems with seeing at night</td>\n",
       "      <td>This drug is highly teratogenic ,females must ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>2709</td>\n",
       "      <td>divigel</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>menopause</td>\n",
       "      <td>My overall mood, sense of well being, energy l...</td>\n",
       "      <td>No side effects of any kind were noted or appa...</td>\n",
       "      <td>Divigel is a topically applied Bio-Identical H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>729</td>\n",
       "      <td>claripel-cream</td>\n",
       "      <td>8</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>acne scarring &amp; hyperpigmentation</td>\n",
       "      <td>Up until 2 years ago, it worked really well on...</td>\n",
       "      <td>Have stopped using it and have also learned th...</td>\n",
       "      <td>Stopped using it for the time being.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4013 rows × 9 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8d3655e-f82f-4070-b915-5de2c32e5f6d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f8d3655e-f82f-4070-b915-5de2c32e5f6d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f8d3655e-f82f-4070-b915-5de2c32e5f6d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-15e4929f-533c-4b72-bb2c-1739e327ac75\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15e4929f-533c-4b72-bb2c-1739e327ac75')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-15e4929f-533c-4b72-bb2c-1739e327ac75 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      Unnamed: 0       urlDrugName  rating           effectiveness  \\\n",
       "0           2202         enalapril       4        Highly Effective   \n",
       "1           3117  ortho-tri-cyclen       1        Highly Effective   \n",
       "2           1146           ponstel      10        Highly Effective   \n",
       "3           3947          prilosec       3    Marginally Effective   \n",
       "4           1951            lyrica       2    Marginally Effective   \n",
       "...          ...               ...     ...                     ...   \n",
       "4008         690          accutane       7  Considerably Effective   \n",
       "4009        1071        proair-hfa      10        Highly Effective   \n",
       "4010         681          accutane       8  Considerably Effective   \n",
       "4011        2709           divigel      10        Highly Effective   \n",
       "4012         729    claripel-cream       8  Considerably Effective   \n",
       "\n",
       "                sideEffects                               condition  \\\n",
       "0         Mild Side Effects  management of congestive heart failure   \n",
       "1       Severe Side Effects                        birth prevention   \n",
       "2           No Side Effects                        menstrual cramps   \n",
       "3         Mild Side Effects                             acid reflux   \n",
       "4       Severe Side Effects                            fibromyalgia   \n",
       "...                     ...                                     ...   \n",
       "4008    Severe Side Effects                           acne vulgaris   \n",
       "4009        No Side Effects                                  asthma   \n",
       "4010  Moderate Side Effects                              serve acne   \n",
       "4011        No Side Effects                               menopause   \n",
       "4012      Mild Side Effects       acne scarring & hyperpigmentation   \n",
       "\n",
       "                                         benefitsReview  \\\n",
       "0     slowed the progression of left ventricular dys...   \n",
       "1     Although this type of birth control has more c...   \n",
       "2     I was used to having cramps so badly that they...   \n",
       "3     The acid reflux went away for a few months aft...   \n",
       "4     I think that the Lyrica was starting to help w...   \n",
       "...                                                 ...   \n",
       "4008  Detoxing effect by pushing out the system thro...   \n",
       "4009  The albuterol relieved the constriction, irrit...   \n",
       "4010                    Serve Acne has turned to middle   \n",
       "4011  My overall mood, sense of well being, energy l...   \n",
       "4012  Up until 2 years ago, it worked really well on...   \n",
       "\n",
       "                                      sideEffectsReview  \\\n",
       "0     cough, hypotension , proteinuria, impotence , ...   \n",
       "1     Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...   \n",
       "2            Heavier bleeding and clotting than normal.   \n",
       "3     Constipation, dry mouth and some mild dizzines...   \n",
       "4     I felt extremely drugged and dopey.  Could not...   \n",
       "...                                                 ...   \n",
       "4008  Hairloss, extreme dry skin, itchiness, raises ...   \n",
       "4009                I have experienced no side effects.   \n",
       "4010    Painfull muscles, problems with seeing at night   \n",
       "4011  No side effects of any kind were noted or appa...   \n",
       "4012  Have stopped using it and have also learned th...   \n",
       "\n",
       "                                         commentsReview  \n",
       "0     monitor blood pressure , weight and asses for ...  \n",
       "1     I Hate This Birth Control, I Would Not Suggest...  \n",
       "2     I took 2 pills at the onset of my menstrual cr...  \n",
       "3     I was given Prilosec prescription at a dose of...  \n",
       "4                                             See above  \n",
       "...                                                 ...  \n",
       "4008  Treatment period is 3 months/12 weeks. Dosage ...  \n",
       "4009  I use the albuterol as needed because of aller...  \n",
       "4010  This drug is highly teratogenic ,females must ...  \n",
       "4011  Divigel is a topically applied Bio-Identical H...  \n",
       "4012               Stopped using it for the time being.  \n",
       "\n",
       "[4013 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create csv file so I can view it clearly\n",
    "output_path = 'data/cleaned_drug_data.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "drug_data.to_csv(output_path, index=False)\n",
    "\n",
    "# Now read the CSV file\n",
    "pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0Cpv6XTfECT"
   },
   "outputs": [],
   "source": [
    "#combine comments and reviews of drug effective, side effects, and other comments into one column\n",
    "\n",
    "#Drop rows with missing or unnamed drug names\n",
    "drug_data = drug_data.dropna(subset=[\"urlDrugName\", \"rating\"])\n",
    "drug_data = drug_data[~drug_data[\"urlDrugName\"].str.lower().str.contains(\"unnamed\", na=False)]\n",
    "\n",
    "#Combine three text fields into one review column\n",
    "drug_data[\"text\"] = (\n",
    "    drug_data[[\"benefitsReview\", \"sideEffectsReview\", \"commentsReview\"]]\n",
    "    .fillna(\"\")\n",
    "    .agg(\" \".join, axis=1)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "#Drop rows where the combined text is empty\n",
    "drug_data = drug_data[drug_data[\"text\"].str.len() > 10]\n",
    "\n",
    "#Drop rows where the combined text is empty\n",
    "drug_data = drug_data[drug_data[\"text\"].str.len() > 10]\n",
    "\n",
    "#Keep only what we need\n",
    "drug_data = drug_data[[\"urlDrugName\", \"rating\", \"effectiveness\", \"sideEffects\", \"condition\", \"text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvtM1QH67gGv",
    "outputId": "c92cff6c-5e7d-40ee-8c07-9a3f5142fefb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size after cleaning: 4,142 reviews\n"
     ]
    }
   ],
   "source": [
    "#describe data\n",
    "import pandas as pd\n",
    "drug_data = pd.concat([pd.read_csv(\"data/drugLibTrain_raw.tsv\", sep=\"\\t\"), pd.read_csv(\"data/drugLibTest_raw.tsv\", sep=\"\\t\")])\n",
    "drug_data[\"text\"] = drug_data[[\"benefitsReview\",\"sideEffectsReview\",\"commentsReview\"]].fillna(\"\").agg(\" \".join, axis=1).str.strip()\n",
    "print(f\"Final dataset size after cleaning: {df[df['text'].str.len()>10].dropna(subset=['urlDrugName','rating']).shape[0]:,} reviews\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wueQY97kfECT",
    "outputId": "552af5a2-713f-4f17-e57c-4751b36866e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    0.676\n",
      "negative    0.181\n",
      "neutral     0.143\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#map out sentiment based on rating\n",
    "\n",
    "def map_sentiment(r):\n",
    "    if r <= 3:\n",
    "        return \"negative\"\n",
    "    elif r <= 6:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "drug_data[\"sentiment\"] = drug_data[\"rating\"].apply(map_sentiment)\n",
    "\n",
    "#view distribution of sentiment\n",
    "\n",
    "sentiment_dist = drug_data[\"sentiment\"].value_counts(normalize=True).round(3)\n",
    "print(sentiment_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPmXFz7BfECU"
   },
   "outputs": [],
   "source": [
    "#split x and y into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    drug_data[\"text\"], drug_data[\"sentiment\"],\n",
    "    test_size=0.2, random_state=42, stratify=drug_data[\"sentiment\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-f9d2Wk-fECU",
    "outputId": "6a9b18f7-0daa-4933-985e-27bce0f8c273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearSVC ===\n",
      "Accuracy: 0.767 | Macro-F1: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.777     0.533     0.632       150\n",
      "     neutral      0.520     0.109     0.181       119\n",
      "    positive      0.775     0.970     0.861       560\n",
      "\n",
      "    accuracy                          0.767       829\n",
      "   macro avg      0.690     0.537     0.558       829\n",
      "weighted avg      0.738     0.767     0.722       829\n",
      "\n",
      "[[ 80   6  64]\n",
      " [ 12  13  94]\n",
      " [ 11   6 543]]\n",
      "\n",
      "=== LogReg ===\n",
      "Accuracy: 0.727 | Macro-F1: 0.428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.955     0.280     0.433       150\n",
      "     neutral      1.000     0.008     0.017       119\n",
      "    positive      0.714     1.000     0.833       560\n",
      "\n",
      "    accuracy                          0.727       829\n",
      "   macro avg      0.890     0.429     0.428       829\n",
      "weighted avg      0.799     0.727     0.644       829\n",
      "\n",
      "[[ 42   0 108]\n",
      " [  2   1 116]\n",
      " [  0   0 560]]\n"
     ]
    }
   ],
   "source": [
    "# Optional: TF-IDF Baseline Models (for comparison only)\n",
    "# Note: These are kept as optional baselines but are not the main modeling approach\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OPTIONAL BASELINE: TF-IDF Models\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Note: Main pipeline uses ClinicalBERT embeddings → PCA → ANN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Uncomment below to run TF-IDF baselines\n",
    "\"\"\"\n",
    "pipelines = {\n",
    "    \"TFIDF+LinearSVC\": Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9, sublinear_tf=True)),\n",
    "        (\"clf\", LinearSVC())\n",
    "    ]),\n",
    "    \"TFIDF+LogReg\": Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9, sublinear_tf=True)),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "    ])\n",
    "}\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1m = f1_score(y_test, preds, average=\"macro\")\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Macro-F1: {f1m:.3f}\")\n",
    "    print(classification_report(y_test, preds, digits=3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f5ac8cf",
    "outputId": "5a128412-5a28-47ac-c2f6-38743813a468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install transformers torch datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xkREUcJ1Vwc",
    "outputId": "4ab796f3-6ee7-4e68-beb2-c33ebf403512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: CPU only\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for ClinicalBERT feature extraction and ANN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU only'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rqcvjgJCcBc",
    "outputId": "7ed90496-0015-43db-ce05-784eb3f018bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'urlDrugName', 'rating', 'effectiveness', 'sideEffects',\n",
      "       'condition', 'benefitsReview', 'sideEffectsReview', 'commentsReview',\n",
      "       'text', 'sentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verify data structure\n",
    "print(\"Data columns:\", drug_data.columns.tolist())\n",
    "print(f\"\\nDataset shape: {drug_data.shape}\")\n",
    "print(f\"Text column: {TEXT_COL}\")\n",
    "print(f\"Label column: {LABEL_COL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GF5VULK4aRql",
    "outputId": "27ae0abd-ebab-4148-f5b7-736220cb3e74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3210,\n",
       " 803,\n",
       " sentiment\n",
       " positive    2707\n",
       " negative     721\n",
       " neutral      585\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# ============================================================\n",
    "# This section loads the data, creates text column, maps ratings to sentiment labels,\n",
    "# and splits into train/validation sets\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"sentiment\"\n",
    "\n",
    "# Load and prepare data\n",
    "import re\n",
    "drug_data = pd.read_csv(\"data/cleaned_drug_data.csv\")\n",
    "\n",
    "# Ensure TEXT_COL exists\n",
    "if TEXT_COL not in drug_data.columns:\n",
    "    preferred = [\"benefitsReview\", \"sideEffectsReview\", \"commentsReview\"]\n",
    "    present = [c for c in preferred if c in drug_data.columns]\n",
    "    if not present:\n",
    "        pat = re.compile(r\"(benefit|side\\s*effect|comment|review|text)\", re.IGNORECASE)\n",
    "        present = [c for c in drug_data.columns if pat.search(str(c))]\n",
    "    if not present:\n",
    "        raise KeyError(\"No text/review columns found to build 'text'.\")\n",
    "    drug_data[TEXT_COL] = (\n",
    "        drug_data[present].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    )\n",
    "\n",
    "# Check LABEL_COL exists (derive from rating if needed)\n",
    "if LABEL_COL not in drug_data.columns:\n",
    "    rating_col = next((c for c in [\"rating\",\"Rating\",\"RATING\"] if c in drug_data.columns), None)\n",
    "    if rating_col is None:\n",
    "        raise KeyError(\"No 'sentiment' column and no 'rating' column to derive it from.\")\n",
    "    def map_sent(r):\n",
    "        try:\n",
    "            r = float(r)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "        if r <= 3: return \"negative\"\n",
    "        if r <= 6: return \"neutral\"\n",
    "        return \"positive\"\n",
    "    drug_data[LABEL_COL] = drug_data[rating_col].apply(map_sent)\n",
    "\n",
    "# Clean text/labels\n",
    "drug_data = drug_data.dropna(subset=[TEXT_COL, LABEL_COL])\n",
    "drug_data[TEXT_COL] = drug_data[TEXT_COL].astype(str).str.strip()\n",
    "drug_data = drug_data[drug_data[TEXT_COL].str.len() > 10]\n",
    "\n",
    "# Map labels -> ids\n",
    "label_order = [\"negative\",\"neutral\",\"positive\"]\n",
    "label2id = {l:i for i,l in enumerate(label_order)}\n",
    "id2label = {i:l for l,i in label2id.items()}\n",
    "drug_data[\"label\"] = drug_data[LABEL_COL].map(label2id)\n",
    "\n",
    "# Safety check\n",
    "bad = drug_data[drug_data[\"label\"].isna()][LABEL_COL].unique()\n",
    "if len(bad):\n",
    "    raise ValueError(f\"Unexpected labels found: {bad}. Expected one of {label_order}.\")\n",
    "\n",
    "# Train/val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(\n",
    "    drug_data[[TEXT_COL,\"label\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=drug_data[\"label\"]\n",
    ")\n",
    "\n",
    "# Convert to Hugging Face Dataset objects\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "print(f\"Train size: {len(train_ds)}, Validation size: {len(val_ds)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(drug_data[LABEL_COL].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372,
     "referenced_widgets": [
      "a5f28c1d0ec04401bfa0deb186dbfcf1",
      "e0fde587921143f48984b402a8354289",
      "6930e32da667485e92b4e3a11c1233cf",
      "0418086872cb4cbda612f9c1b919eac3",
      "28d357c55fe4479fbe185ca5e46f2c5f",
      "4aa1ea91fd9841608ec66a9198f7b55b",
      "d7858c0bacc54e27a60b0ca94e5a5ea7",
      "ad76b50329ab4d77bfe59fc369a628e2",
      "3c42e656ff7d421bbf5a0c5677d4ccd5",
      "b5377d94644f46398db76e9997a1f764",
      "8134953cfe91489baf2c892d106c6e00",
      "f3f80a150ba4403297f9d48c85a47eca",
      "50b9b9f7b05d480996336c9801278852",
      "6cc776fe362841ba97ec1c06e71f728b",
      "4ccdd2902cdb4af2ae5b37ad67f0ae32",
      "14dc6959a16e40588d2c31d66308d469",
      "626142ed30fb47d3b258a029e3026a5f",
      "5c21b6a4f68e4c17ab2a7dd77f4b0acf",
      "5d8c855bfd42499c92ef99f26b2c957e",
      "8e9bcb6a6d334609bd1c5a568110c478",
      "2ad594c27efa46c48d8fa6a2fee70d80",
      "1d4924863abc40a5b64a60a3d016a73b",
      "fb21aaaf0e2345259bc88bf706368a5e",
      "c21cabff02474ea3957a56a7e5c4420d",
      "6fffc44e048f4c4e9b5d457420cae43c",
      "ddad907581134e91b5d88bc58933bf94",
      "491a8d1bca96447ea1d7fcd9cb62625b",
      "cec25c1ddfef45a59a87bbf5bc9afb48",
      "19b2061910c549259b248bb78a7d6af5",
      "f8f58f32f24d4f6785f2fbbc0ae8fdd7",
      "115f4f9bdd3d4f37bd34139a5b47cde8",
      "ae8a36536cc04fd58e8d753a8600a2e9",
      "817ca7bede284ca390a995f66fab927f",
      "6bb34b3df09e4c3db31f105f65c25cd7",
      "05a5df2223d74de28542da3eac9ba496",
      "98083eec562a47ee81ac38ccc55841b5",
      "c9c85a132658461e8956703c78001d48",
      "419d9f887d8c4ac08315c2051d594064",
      "cc2fdcd0f0f34cf5806d0af738705e24",
      "c1198cd752af458a81a1a2890249ac6a",
      "d4514973252b4e3e81a13239384cc6f7",
      "bdc618b8f25649b393407725f3875de2",
      "a719f3358fde43b9b960e71114852b06",
      "02be5c985808448789285731ec34d77b",
      "00d9f24630064bad9d4c1f09483eb75f",
      "a93230527435418680aa505e57accd2a",
      "e5ac7efa63104193845f73faca041569",
      "9ba82f4ed792474fad14d62fdd8ecc84",
      "5c9285583a7846a68348a9cf4d10834c",
      "e6e0d4d832464e93959776e9e70c327a",
      "52998323d10248a1b66145d4d1671f1c",
      "2dd5252561234cb6840ae6cb0a7c3451",
      "a31441d4cfdb442cb2c76c7b8d044b32",
      "d9f22d49ce0d4945a76b3b457a75a5f5",
      "7b597dca5cf941e8b16c7491b810b8ab",
      "8568f10ec2594fd289652d5548254771",
      "f922ae227d554968972eaccbb793e9a5",
      "4ce2408a6a704122937705516cdc8a37",
      "f08847a5f06348548d44cf12cdfe6778",
      "2fceeaecba8a475d98934c2c17b5a6d6",
      "51dea9b350cf41d6b1ac6066c2a881bd",
      "0d5c5d07158a4121ad5ba48d1b8b7d28",
      "b18d7045a25344babf8e9cfc5f829131",
      "75c89d166bfe4ba8b0c4d2edd2560590",
      "09465e0621a94164800a754c57effe28",
      "4f114b4327304f8e9755695159d851d9"
     ]
    },
    "id": "GDnyzmT5Bd29",
    "outputId": "8cfa8aae-b90a-4470-a643-16e1cd29510a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 1: CLINICALBERT EMBEDDING EXTRACTION\n",
    "# ============================================================\n",
    "# Load ClinicalBERT tokenizer and encoder model for feature extraction\n",
    "# (not fine-tuning - we extract embeddings from the pre-trained model)\n",
    "\n",
    "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "MAX_LEN = 256\n",
    "\n",
    "print(\"Loading ClinicalBERT tokenizer and encoder...\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "enc_model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "enc_model.eval()  # Set to evaluation mode (no gradient computation)\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Model hidden size: {enc_model.config.hidden_size}\")\n",
    "\n",
    "# Tokenize datasets\n",
    "def tokenize_for_enc(batch):\n",
    "    \"\"\"Tokenize text for embedding extraction\"\"\"\n",
    "    return tok(\n",
    "        batch[TEXT_COL], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "print(\"\\nTokenizing datasets...\")\n",
    "train_tok = train_ds.map(tokenize_for_enc, batched=True)\n",
    "val_tok = val_ds.map(tokenize_for_enc, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "print(f\"Train tokenized: {len(train_tok)} samples\")\n",
    "print(f\"Val tokenized: {len(val_tok)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231,
     "referenced_widgets": [
      "e1f344f4a4a844398b91dc4197284845",
      "499946b66ebc4193974846b2d305f897",
      "13b29f7aab64428f9f2539c28479dd41",
      "987b4870dd7247cca5774cffea39f500",
      "3d6c64acabbe4034adf34ac0320e8356",
      "2819775a883f460081c44072cf840d31",
      "74819db13dae4c23990688df34949c09",
      "48e5142f9fd8462aac74ce0685c28359",
      "a082c242773848b9b00ec80de7bdd3e1",
      "11ab5838387f4ef0b2f3225ce11762ed",
      "4d23bf8bfd534483995859146f9516cc",
      "38774a3f7b45458fa860645003ff8b0d",
      "f0b869ddbb6a4f62bb823e6d1671b0d2",
      "435911880511407b83445f807b43b1fc",
      "b65ba47a60e94f078d4377b13519050c",
      "acef2d7c998e4cd991480d9a86e25245",
      "9342bbb9421f48b9b1dff1af699e23e6",
      "2913b379d1c3461babd622fff119289c",
      "55a73caa304f4956af0d4327cd9e9308",
      "4277b38a32bd411ea9412e5628ae399a",
      "db00512c3a354d96a51ef407e7826f13",
      "d726a08b83f844adbe836d1a87a4739c"
     ]
    },
    "id": "4i5Xw1nFBhB0",
    "outputId": "b5484db0-32b1-45a6-dcf7-10b9a363322a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2484839369.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='166' max='603' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/603 1:56:06 < 5:09:24, 0.02 it/s, Epoch 0.82/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract [CLS] token embeddings from ClinicalBERT\n",
    "# This function processes batches and extracts the [CLS] token embedding (first token)\n",
    "\n",
    "def get_cls_embeddings(dataset, batch_size=16):\n",
    "    \"\"\"\n",
    "    Extract [CLS] token embeddings from ClinicalBERT for all samples in dataset.\n",
    "    \n",
    "    Returns:\n",
    "        X_emb: numpy array of shape (N, 768) - BERT embeddings\n",
    "        y: numpy array of shape (N,) - integer labels\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(f\"Extracting embeddings from {len(dataset)} samples...\")\n",
    "    with torch.no_grad():  # No gradient computation needed\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].cpu().numpy()\n",
    "            \n",
    "            # Forward pass through encoder\n",
    "            outputs = enc_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Extract [CLS] token embedding (first token, index 0)\n",
    "            cls_emb = outputs.last_hidden_state[:, 0, :]  # Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            all_embeddings.append(cls_emb.cpu().numpy())\n",
    "            all_labels.append(labels)\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"  Processed {i + 1} batches...\")\n",
    "    \n",
    "    X_emb = np.vstack(all_embeddings)\n",
    "    y = np.concatenate(all_labels)\n",
    "    \n",
    "    print(f\"Extracted embeddings shape: {X_emb.shape}\")\n",
    "    print(f\"Labels shape: {y.shape}\")\n",
    "    \n",
    "    return X_emb, y\n",
    "\n",
    "# Extract embeddings for train and validation sets\n",
    "print(\"=\" * 60)\n",
    "print(\"Extracting ClinicalBERT Embeddings\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_bert, y_train = get_cls_embeddings(train_tok, batch_size=16)\n",
    "X_val_bert, y_val = get_cls_embeddings(val_tok, batch_size=16)\n",
    "\n",
    "print(f\"\\nTrain embeddings: {X_train_bert.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"Val embeddings: {X_val_bert.shape}, Labels: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkYZ8yoCBjaS"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: PCA DIMENSIONALITY REDUCTION\n",
    "# ============================================================\n",
    "# Standardize BERT embeddings and apply PCA to reduce dimensionality\n",
    "# This makes the features more manageable for the ANN classifier\n",
    "\n",
    "# Hyperparameter: number of PCA components\n",
    "N_COMPONENTS = 50  # Adjustable: try 32, 50, 100, etc.\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Applying PCA to BERT Embeddings\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Standardize features\n",
    "print(\"Standardizing embeddings...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_bert)\n",
    "X_val_scaled = scaler.transform(X_val_bert)\n",
    "\n",
    "# Apply PCA\n",
    "print(f\"Applying PCA with {N_COMPONENTS} components...\")\n",
    "pca = PCA(n_components=N_COMPONENTS, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "print(f\"\\nOriginal embedding dimension: {X_train_bert.shape[1]}\")\n",
    "print(f\"PCA reduced dimension: {X_train_pca.shape[1]}\")\n",
    "print(f\"Variance explained by {N_COMPONENTS} components: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "print(f\"\\nTrain PCA features shape: {X_train_pca.shape}\")\n",
    "print(f\"Val PCA features shape: {X_val_pca.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOydy1W-Blu0"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: FEEDFORWARD ANN CLASSIFIER\n",
    "# ============================================================\n",
    "# Build a simple feedforward neural network that takes PCA features\n",
    "# as input and outputs 3 sentiment classes\n",
    "\n",
    "# Define ANN architecture\n",
    "input_dim = X_train_pca.shape[1]\n",
    "num_classes = 3\n",
    "\n",
    "class SentimentANN(nn.Module):\n",
    "    \"\"\"\n",
    "    Feedforward neural network for sentiment classification.\n",
    "    Input: PCA-reduced BERT embeddings\n",
    "    Output: 3 sentiment classes (negative, neutral, positive)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden=64, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Create PyTorch datasets and dataloaders\n",
    "train_dataset = TensorDataset(\n",
    "    torch.FloatTensor(X_train_pca), \n",
    "    torch.LongTensor(y_train)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.FloatTensor(X_val_pca), \n",
    "    torch.LongTensor(y_val)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = SentimentANN(in_dim=input_dim, hidden=64, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Training Feedforward ANN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Model architecture:\\n{model}\")\n",
    "print(f\"\\nTraining on {len(train_dataset)} samples, validating on {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xxe28_MUlpE3"
   },
   "outputs": [],
   "source": [
    "# Training loop for ANN\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "print(f\"\\nTraining for {NUM_EPOCHS} epochs...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_val_preds = []\n",
    "    all_val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            val_total += batch_y.size(0)\n",
    "            val_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "            all_val_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    val_acc = val_correct / val_total\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"macro\")\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"  Val Macro F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ✓ New best validation accuracy!\")\n",
    "    print()\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Loaded best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 4: EVALUATION AND RESULTS\n",
    "# ============================================================\n",
    "# Evaluate the ANN model and generate classification report and confusion matrix\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Final Evaluation: ANN on ClinicalBERT+PCA Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get predictions on validation set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_x)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "y_pred_ann = np.array(all_preds)\n",
    "y_true_ann = np.array(all_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "acc_ann = accuracy_score(y_true_ann, y_pred_ann)\n",
    "f1_ann = f1_score(y_true_ann, y_pred_ann, average=\"macro\")\n",
    "recall_ann = recall_score(y_true_ann, y_pred_ann, average=\"macro\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_true_ann, y_pred_ann, \n",
    "    target_names=label_order, \n",
    "    digits=3\n",
    "))\n",
    "\n",
    "# Create performance summary\n",
    "ann_metrics = {\n",
    "    \"model\": \"ClinicalBERT+PCA+ANN\",\n",
    "    \"accuracy\": acc_ann,\n",
    "    \"macro_recall\": recall_ann,\n",
    "    \"macro_f1\": f1_ann\n",
    "}\n",
    "\n",
    "perf_df = pd.DataFrame([ann_metrics])\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Performance Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(perf_df.to_string(index=False))\n",
    "print(f\"\\nAccuracy: {acc_ann:.3f}\")\n",
    "print(f\"Macro Recall: {recall_ann:.3f}\")\n",
    "print(f\"Macro F1: {f1_ann:.3f}\")\n",
    "\n",
    "# Confusion matrix (row-normalized percentages)\n",
    "cm_ann = confusion_matrix(y_true_ann, y_pred_ann, labels=[0,1,2])\n",
    "\n",
    "def confusion_percent(cm_counts):\n",
    "    \"\"\"Return row-normalized confusion matrix in percentages.\"\"\"\n",
    "    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "        row_sums = cm_counts.sum(axis=1, keepdims=True)\n",
    "        return np.where(row_sums > 0, (cm_counts / row_sums) * 100.0, 0.0)\n",
    "\n",
    "cm_ann_pct = confusion_percent(cm_ann)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(cm_ann_pct, cmap=\"Blues\", aspect=\"auto\")\n",
    "plt.colorbar(im, label=\"Row %\")\n",
    "plt.title(\"Confusion Matrix - ClinicalBERT+PCA+ANN\\n(Row-normalized percentages)\", fontsize=12)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks([0,1,2], label_order)\n",
    "plt.yticks([0,1,2], label_order)\n",
    "\n",
    "# Add text annotations\n",
    "for (i, j), val in np.ndenumerate(cm_ann_pct):\n",
    "    plt.text(j, i, f\"{val:.1f}%\", ha=\"center\", va=\"center\", fontsize=11, \n",
    "             color=\"white\" if val > 50 else \"black\", weight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print raw confusion matrix counts\n",
    "print(\"\\nConfusion Matrix (raw counts):\")\n",
    "print(cm_ann)\n",
    "print(f\"\\nRow-normalized percentages:\")\n",
    "print(cm_ann_pct)\n",
    "\n",
    "# Save results\n",
    "perf_df.to_csv(\"model_performance_comparison.csv\", index=False)\n",
    "print(\"\\nSaved: model_performance_comparison.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}